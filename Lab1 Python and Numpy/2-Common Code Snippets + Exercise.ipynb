{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic File Input Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]]\n"
     ]
    }
   ],
   "source": [
    "myfile = open('float_data.txt')\n",
    "data = []\n",
    "for line in myfile:\n",
    "    numbers = line.split()\n",
    "    nums_list = [float(x) for x in numbers]\n",
    "    data.append(nums_list)\n",
    "\n",
    "    \n",
    "data = np.array(data)\n",
    "print data\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy way of data from loading text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]]\n",
      "[[ 1.  2.  4.]\n",
      " [ 5.  6.  8.]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.loadtxt('float_data.txt')\n",
    "print arr\n",
    "print arr[:,[0,1,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy way of loading complicated text\n",
    "\n",
    "Have a look at the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.loadtxt('float_data_with_header.txt',skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: \n",
    "\n",
    "Load the data from complex_data_file.txt and ignore the comments, and the 4th column\n",
    "\n",
    "tip: execute the following for the documentation np.loadtxt?\n",
    "\n",
    "the output should be \n",
    "\n",
    "array([\n",
    "\n",
    "[   1,    1, 2000,   30],\n",
    "\n",
    "[   2,    1, 2000,   41],\n",
    "\n",
    "[   4,    1, 2000,   55],\n",
    "\n",
    "[   5,    1, 2000,   78],\n",
    "\n",
    "[   6,    1, 2000,  134],\n",
    "\n",
    "[   7,    1, 2000,   42]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.loadtxt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('mysaveddata.txt',arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tips:\n",
    "- Use numpy loading methods when the file has consistent types, and go for pandas methods if the file contains a mixture of data type.\n",
    "- Use H5py library for loading and saving large files, it's more efficient than csv and txt.\n",
    "\n",
    "<img src=\"imgs/fileformats.PNG\" height=\"600\" width = \"800\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "for the following image, write a single line to slice each of the marked colored regions\n",
    "<img src=\"imgs/Ex1.PNG\" height=\"400\" width = \"400\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how to create this array ?\n",
    "\n",
    "## try to use broadcasting to create the above array\n",
    "\n",
    "## slice the green \n",
    "\n",
    "## slice the red\n",
    "\n",
    "## slice the blue\n",
    "\n",
    "## slice the orange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy fancy indexing\n",
    "\n",
    "The goal of the following is to slice something that is irregular\n",
    "<img src=\"imgs/im2.PNG\" height=\"200\" width = \"400\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.arange(0,80,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 50] [10 20 50]\n"
     ]
    }
   ],
   "source": [
    "## indexing by indices\n",
    "indices = [1,2,-3]\n",
    "y = a[indices]\n",
    "\n",
    "\n",
    "## indexing by masks\n",
    "mask1= a < 30\n",
    "mask2= a > 0\n",
    "mask3 = a == 50\n",
    "mask = (mask & mask2) |mask3\n",
    "mask\n",
    "z = a[mask]\n",
    "print y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'dog',\n",
       " '2': 'cat',\n",
       " '3': 'car',\n",
       " '4': 'motorbike',\n",
       " '5': 'man',\n",
       " '6': 'child',\n",
       " '7': 'door',\n",
       " '8': 'window'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import the classids.txt file as a dictionary in one line\n",
    "fi  = open('classids.txt').readlines()\n",
    "classids_dict = dict(line.strip().split(' ') for line in open('classids.txt').readlines() )\n",
    "classids_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\wheelchair\\\\bicycle\\\\bicycle0000.jpg', 'E:\\\\wheelchair\\\\bicycle\\\\bicycle0001.jpg', 'E:\\\\wheelchair\\\\bicycle\\\\bicycle0002.jpg', 'E:\\\\wheelchair\\\\bicycle\\\\bicycle0003.jpg', 'E:\\\\wheelchair\\\\bicycle\\\\bicycle0004.jpg']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "fnames=  list(glob.iglob('E:\\\\wheelchair\\\\bicycle\\\\*.jpg'))\n",
    "\n",
    "print fnames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise on Selection and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Enthought, Inc. All Rights Reserved\n",
    "\"\"\"\n",
    "Dow Selection\n",
    "-------------\n",
    "\n",
    "Topics: Boolean array operators, sum function, where function, plotting.\n",
    "\n",
    "The array 'dow' is a 2-D array with each row holding the\n",
    "daily performance of the Dow Jones Industrial Average from the\n",
    "beginning of 2008 (dates have been removed for exercise simplicity).\n",
    "The array has the following structure::\n",
    "\n",
    "       OPEN      HIGH      LOW       CLOSE     VOLUME      ADJ_CLOSE\n",
    "       13261.82  13338.23  12969.42  13043.96  3452650000  13043.96\n",
    "       13044.12  13197.43  12968.44  13056.72  3429500000  13056.72\n",
    "       13046.56  13049.65  12740.51  12800.18  4166000000  12800.18\n",
    "       12801.15  12984.95  12640.44  12827.49  4221260000  12827.49\n",
    "       12820.9   12998.11  12511.03  12589.07  4705390000  12589.07\n",
    "       12590.21  12814.97  12431.53  12735.31  5351030000  12735.31\n",
    "\n",
    "0. The data has been loaded from a .csv file for you.\n",
    "1. Create a \"mask\" array that indicates which rows have a volume\n",
    "   greater than 5.5 billion.\n",
    "2. How many are there?  (hint: use sum).\n",
    "3. Find the index of every row (or day) where the volume is greater\n",
    "   than 5.5 billion. hint: look at the where() command.\n",
    "\n",
    "Bonus\n",
    "~~~~~\n",
    "\n",
    "1. Plot the adjusted close for *every* day in 2008.\n",
    "2. Now over-plot this plot with a 'red dot' marker for every\n",
    "   day where the volume was greater than 5.5 billion.\n",
    "\n",
    "See :ref:`dow-selection-solution`.\n",
    "\"\"\"\n",
    "\n",
    "from numpy import loadtxt, sum, where\n",
    "from matplotlib.pyplot import figure, hold, plot, show\n",
    "\n",
    "# Constants that indicate what data is held in each column of\n",
    "# the 'dow' array.\n",
    "OPEN = 0\n",
    "HIGH = 1\n",
    "LOW = 2\n",
    "CLOSE = 3\n",
    "VOLUME = 4\n",
    "ADJ_CLOSE = 5\n",
    "\n",
    "# 0. The data has been loaded from a .csv file for you.\n",
    "\n",
    "# 'dow' is our NumPy array that we will manipulate.\n",
    "dow = loadtxt('dow.csv', delimiter=',')\n",
    "\n",
    "# 1. Create a \"mask\" array that indicates which rows have a volume\n",
    "#    greater than 5.5 billion.\n",
    "\n",
    "\n",
    "# 2. How many are there?  (hint: use sum).\n",
    "\n",
    "# 3. Find the index of every row (or day) where the volume is greater\n",
    "#    than 5.5 billion. hint: look at the where() command.\n",
    "\n",
    "# BONUS:\n",
    "# a. Plot the adjusted close for EVERY day in 2008.\n",
    "# b. Now over-plot this plot with a 'red dot' marker for every\n",
    "#    day where the volume was greater than 5.5 billion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise on Numpy Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Enthought, Inc. All Rights Reserved\n",
    "\"\"\"\n",
    "Wind Statistics\n",
    "----------------\n",
    "\n",
    "Topics: Using array methods over different axes, fancy indexing.\n",
    "\n",
    "1. The data in 'wind.data' has the following format::\n",
    "\n",
    "        61  1  1 15.04 14.96 13.17  9.29 13.96  9.87 13.67 10.25 10.83 12.58 18.50 15.04\n",
    "        61  1  2 14.71 16.88 10.83  6.50 12.62  7.67 11.50 10.04  9.79  9.67 17.54 13.83\n",
    "        61  1  3 18.50 16.88 12.33 10.13 11.17  6.17 11.25  8.04  8.50  7.67 12.75 12.71\n",
    "\n",
    "   The first three columns are year, month and day.  The\n",
    "   remaining 12 columns are average windspeeds in knots at 12\n",
    "   locations in Ireland on that day.\n",
    "\n",
    "   Use the 'loadtxt' function from numpy to read the data into\n",
    "   an array.\n",
    "\n",
    "2. Calculate the min, max and mean windspeeds and standard deviation of the\n",
    "   windspeeds over all the locations and all the times (a single set of numbers\n",
    "   for the entire dataset).\n",
    "\n",
    "3. Calculate the min, max and mean windspeeds and standard deviations of the\n",
    "   windspeeds at each location over all the days (a different set of numbers\n",
    "   for each location)\n",
    "\n",
    "4. Calculate the min, max and mean windspeed and standard deviations of the\n",
    "   windspeeds across all the locations at each day (a different set of numbers\n",
    "   for each day)\n",
    "\n",
    "5. Find the location which has the greatest windspeed on each day (an integer\n",
    "   column number for each day).\n",
    "\n",
    "6. Find the year, month and day on which the greatest windspeed was recorded.\n",
    "\n",
    "7. Find the average windspeed in January for each location.\n",
    "\n",
    "You should be able to perform all of these operations without using a for\n",
    "loop or other looping construct.\n",
    "\n",
    "Bonus\n",
    "~~~~~\n",
    "\n",
    "1. Calculate the mean windspeed for each month in the dataset.  Treat\n",
    "   January 1961 and January 1962 as *different* months. (hint: first find a\n",
    "   way to create an identifier unique for each month. The second step might\n",
    "   require a for loop.)\n",
    "\n",
    "2. Calculate the min, max and mean windspeeds and standard deviations of the\n",
    "   windspeeds across all locations for each week (assume that the first week\n",
    "   starts on January 1 1961) for the first 52 weeks. This can be done without\n",
    "   any for loop.\n",
    "\n",
    "Bonus Bonus\n",
    "~~~~~~~~~~~\n",
    "\n",
    "Calculate the mean windspeed for each month without using a for loop.\n",
    "(Hint: look at `searchsorted` and `add.reduceat`.)\n",
    "\n",
    "Notes\n",
    "~~~~~\n",
    "\n",
    "These data were analyzed in detail in the following article:\n",
    "\n",
    "   Haslett, J. and Raftery, A. E. (1989). Space-time Modelling with\n",
    "   Long-memory Dependence: Assessing Ireland's Wind Power Resource\n",
    "   (with Discussion). Applied Statistics 38, 1-50.\n",
    "\n",
    "\n",
    "See :ref:`wind-statistics-solution`.\n",
    "\"\"\"\n",
    "\n",
    "from numpy import loadtxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
